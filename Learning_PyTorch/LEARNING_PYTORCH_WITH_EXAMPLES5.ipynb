{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LEARNING_PYTORCH_WITH_EXAMPLES5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxXFI5xwl28XJyqA+RqLmE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qSPcCXoNAOzv"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = np.random.randn(N, D_in)\n",
        "y = np.random.randn(N, D_out)\n",
        "\n",
        "w1 = np.random.randn(D_in, H)\n",
        "w2 = np.random.randn(H, D_out)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    h = x.dot(w1)\n",
        "    h_relu = np.maximum(h, 0)\n",
        "    y_pred = h_relu.dot(w2)\n",
        "\n",
        "    loss = np.square(y_pred - y).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
        "    grad_h = grad_h_relu.copy()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJeBko4MAbCM",
        "outputId": "77afb69b-4d52-4607-fed8-dd2f498e2d3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 387.2296775632147\n",
            "199 1.5941975963686308\n",
            "299 0.01060848683411815\n",
            "399 8.151400737417395e-05\n",
            "499 6.87148300606987e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1_unlearned = np.random.randn(D_in, H)\n",
        "w2_unlearned = np.random.randn(H, D_out)\n",
        "\n",
        "h = x.dot(w1_unlearned)\n",
        "h_relu = np.maximum(h, 0)\n",
        "y_pred = h_relu.dot(w2_unlearned)\n",
        "print(f\"学習前出力：{np.round(y_pred[0], decimals=2)}\")\n",
        "\n",
        "h = x.dot(w1)\n",
        "h_relu = np.maximum(h, 0)\n",
        "y_pred = h_relu.dot(w2)\n",
        "print(f\"学習後出力：{np.round(y_pred[0], decimals=2)}\")\n",
        "\n",
        "print(f\"目的の出力：{np.round(y[0], decimals=2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaVYRE1mCEp-",
        "outputId": "56dc8119-dd43-409d-8f79-9050d0cd09d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習前出力：[  77.46 -181.45   91.57  137.71 -124.79 -298.5   -30.51 -171.85    0.41\n",
            "   76.39]\n",
            "学習後出力：[-0.13 -0.45  2.16  2.64 -2.68 -1.37  0.94  2.84 -2.6   0.82]\n",
            "目的の出力：[-0.13 -0.45  2.16  2.64 -2.68 -1.37  0.94  2.84 -2.6   0.82]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgx2K1-EDM1k",
        "outputId": "397ab86a-bf91-4a67-d94c-20db08367bae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 567.7606811523438\n",
            "199 2.815385103225708\n",
            "299 0.022916777059435844\n",
            "399 0.0004143454716540873\n",
            "499 5.141844667377882e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
        "\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnXn9KCOFLwH",
        "outputId": "5f6ca2e1-0c90-4c96-9aac-8c5fea0ef631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 851.1004028320312\n",
            "199 10.551321983337402\n",
            "299 0.26143473386764526\n",
            "399 0.007816169410943985\n",
            "499 0.0004651758645195514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class MyReLU(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    relu = MyReLU.apply\n",
        "    \n",
        "    y_pred = relu(x.mm(w1)).mm(w2)\n",
        "\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsXJUxoSIjjC",
        "outputId": "50625536-4c23-4c54-9561-b43bcd2d03f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 706.0306396484375\n",
            "199 4.275500297546387\n",
            "299 0.035569269210100174\n",
            "399 0.0005585404578596354\n",
            "499 6.408237823052332e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZVshaSKK3l1",
        "outputId": "727e2afc-e5f1-4ab7-9f97-8e135dee0783"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 2.099937915802002\n",
            "199 0.026093289256095886\n",
            "299 0.0006283351685851812\n",
            "399 1.9646078726509586e-05\n",
            "499 6.954660420888104e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpTUHXlNMAQ",
        "outputId": "1010ab3c-86da-4de7-c5c3-60c6f7ff8eee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 42.87982177734375\n",
            "199 0.646184504032135\n",
            "299 0.003008028259500861\n",
            "399 1.1764821465476416e-05\n",
            "499 3.006900683999447e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_relu = self.linear1(x).clamp(min=0)\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "for t in range(500):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G79hKnXVPNqn",
        "outputId": "92aaf1b2-215d-4154-c295-3293d1618ad6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 3.7193377017974854\n",
            "199 0.05849664285778999\n",
            "299 0.001769042108207941\n",
            "399 7.57279121899046e-05\n",
            "499 3.81971949536819e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "\n",
        "        super(DynamicNet, self).__init__()\n",
        "        self.input_linear = torch.nn.Linear(D_in, H)\n",
        "        self.middle_linear = torch.nn.Linear(H, H)\n",
        "        self.output_linear = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h_relu = self.input_linear(x).clamp(min=0)\n",
        "        for _ in range(random.randint(0, 4)):\n",
        "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
        "        y_pred = self.output_linear(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = DynamicNet(D_in, H, D_out)\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "for t in range(500):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-HvNS2NQs2M",
        "outputId": "675ee6a6-f647-4612-e44c-045d0a069317"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 140.29220581054688\n",
            "199 5.786439418792725\n",
            "299 3.607691764831543\n",
            "399 7.771110534667969\n",
            "499 0.929389476776123\n"
          ]
        }
      ]
    }
  ]
}